{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Model Scaling Laws Tutorial\n",
    "\n",
    "This notebook is meant to provide a basic tutorial on how to use the data and models released for the paper \"Scaling Laws for Language Encoding Models fMRI. As this is a scaling laws paper, be aware many of the files used by this notebook are ***large***. This notebook was tested on a machine with 128GB of RAM. We start with a few dependencies. The ridge_utils folder can be found in the same repository as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#### Dependencies ####\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# This dependency is pycortex, which enables the plotting of flatmaps. It can be disabled.\n",
    "import cortex\n",
    "# from cvxopt import matrix, solvers # Only necessary for the stacked model.\n",
    "# Only necessary for feature extraction.\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Repository imports\n",
    "from tpr.ridge_utils.ridge import bootstrap_ridge\n",
    "import tpr.ridge_utils.npp\n",
    "from tpr.ridge_utils.util import make_delayed\n",
    "from tpr.ridge_utils.dsutils import make_word_ds\n",
    "from tpr.ridge_utils.DataSequence import DataSequence\n",
    "from tpr.ridge_utils.tokenization_helpers import generate_efficient_feat_dicts_opt\n",
    "from tpr.ridge_utils.tokenization_helpers import convert_to_feature_mats_opt\n",
    "\n",
    "# Some extra helper functions\n",
    "\n",
    "\n",
    "def zscore(v): return (v - v.mean(0)) / v.std(0)\n",
    "\n",
    "\n",
    "zscore.__doc__ = \"\"\"Z-scores (standardizes) each column of [v].\"\"\"\n",
    "zs = zscore\n",
    "\n",
    "# Matrix corr -- find correlation between each column of c1 and the corresponding column of c2\n",
    "\n",
    "\n",
    "def mcorr(c1, c2): return (zs(c1) * zs(c2)).mean(0)\n",
    "\n",
    "\n",
    "mcorr.__doc__ = \"\"\"Matrix correlation. Find the correlation between each column of [c1] and the corresponding column of [c2].\"\"\"\n",
    "\n",
    "# Ignore irrelevant warnings that muck up the notebook\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Some parameters\n",
    "NUM_VOX = 95556  # Number of voxels in the subject we plan to use\n",
    "NUM_TRS = 790  # Number of TRs across 3 test stories\n",
    "trim_start = 50  # Trim 50 TRs off the start of the story\n",
    "trim_end = 5  # Trim 5 off the back\n",
    "ndelays = 4  # We use 4 FIR delays (2 seconds, 4 seconds, 6 seconds, 8 seconds)\n",
    "delays = range(1, ndelays + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Encoding Model with pre-generated features\n",
    "\n",
    "We start by building a basic semantic encoding model from layer 33 of OPT-30B using the preexisting features, weights, and responses from the [Box folder](https://utexas.box.com/v/EncodingModelScalingLaws). We load the features, apply some basic processing steps, and then dot the features with the encoding model weights to get our voxelwise predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Running a basic semantic encoding model built from OPT layer 33 ###\n",
    "\n",
    "# We are going to test our model on one of our held-out stories, \"wheretheressmoke\".\n",
    "Tstories = ['wheretheressmoke']\n",
    "\n",
    "# Load the precomputed OPT model hidden states from the Box\n",
    "# From semantic_features folder\n",
    "features = joblib.load(\"downsampled_featureseqs_opt33b_layer33.jbl\")\n",
    "\n",
    "\n",
    "# Trim and zscore the model features\n",
    "Tstim = np.nan_to_num(np.vstack([tpr.ridge_utils.npp.zs(\n",
    "    features[story][trim_start:-trim_end]) for story in Tstories]))\n",
    "\n",
    "# Add FIR delays\n",
    "delTstim = make_delayed(Tstim, delays)\n",
    "\n",
    "# Load the linear encoding model weights for subject S02\n",
    "# From ridge_weights folder\n",
    "wt = joblib.load(\"S3_opt33b_wts_layer33.jbl\")\n",
    "\n",
    "# Dot the weights with the features to get voxelwise model predictions\n",
    "pred = np.dot(delTstim,  wt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a basic noise ceiling analysis using our new predictions. We will use the method of [Schoppe et al.](https://www.frontiersin.org/articles/10.3389/fncom.2016.00010/full), as we did  in our paper. Below is a short code snippet that implements their noise ceiling estimation method. We load the ground truth responses and compare them to our predictions using this code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spe_and_cc_norm(orig_data, data_pred, data_norm=True, max_flooring=None):\n",
    "    '''\n",
    "    Computes the signal power explained and the cc_norm of a model given the observed and predicted values\n",
    "    Assumes normalization unless data_norm is set to False\n",
    "\n",
    "    orig_data: 3D numpy array (trials, timepoints, voxels)\n",
    "\n",
    "    data_pred: 2D numpy array (timepoints, voxels)\n",
    "\n",
    "    data_norm: bool -> Set to False if not pre-normalized\n",
    "\n",
    "    max_flooring: None/float (0-1) -> If not None, compute cc_norm in an alternate way that floors cc_max by max_flooring.\n",
    "    This is helpful to clean up bad voxels that are not at all language selective.\n",
    "\n",
    "    According to Schoppe: https://www.frontiersin.org/articles/10.3389/fncom.2016.00010/full\n",
    "    '''\n",
    "    y = np.mean(orig_data, axis=0)\n",
    "    num_trials = len(orig_data)\n",
    "    if not data_norm:\n",
    "        variance_across_time = np.var(orig_data, axis=1, ddof=1)\n",
    "        TP = np.mean(variance_across_time, axis=0)\n",
    "    else:\n",
    "        TP = np.zeros(orig_data.shape[2]) + 1\n",
    "    SP = (1 / (num_trials-1)) * ((num_trials * np.var(y, axis=0, ddof=1)) - TP)\n",
    "    SPE_num = (np.var(y, axis=0, ddof=1) -\n",
    "               np.var(y - data_pred, axis=0, ddof=1))\n",
    "    SPE = (np.var(y, axis=0, ddof=1) -\n",
    "           np.var(y - data_pred, axis=0, ddof=1)) / SP\n",
    "    y_flip = np.swapaxes(y, axis1=0, axis2=1)\n",
    "    data_flip = np.swapaxes(data_pred, axis1=0, axis2=1)\n",
    "    covs = np.zeros(y_flip.shape[0])\n",
    "    for i, row in enumerate(y_flip):\n",
    "        covs[i] = np.cov(y_flip[i], data_flip[i])[0][1]\n",
    "    cc_norm = np.sqrt(1/SP) * \\\n",
    "        (covs / np.sqrt(np.var(data_pred, axis=0, ddof=1)))\n",
    "    cc_max = None\n",
    "    if max_flooring is not None:\n",
    "        cc_max = np.nan_to_num(\n",
    "            1 / (np.sqrt(1 + ((1/num_trials) * ((TP/SP)-1)))))\n",
    "        # cc_max = np.maximum(cc_max, np.zeros(cc_max.shape) + max_flooring)\n",
    "        corrs = np.zeros(y_flip.shape[0])\n",
    "        for i, row in enumerate(y_flip):\n",
    "            corrs[i] = np.corrcoef(y_flip[i], data_flip[i])[0][1]\n",
    "        cc_norm = corrs / cc_max\n",
    "    return SPE, cc_norm, cc_max, corrs\n",
    "\n",
    "\n",
    "# From responses folder\n",
    "tensessions = joblib.load(\"tensessions_wheretheressmoke_S03.jbl\")\n",
    "SPE, cc_norm, cc_max, corrs_unnorm = spe_and_cc_norm(\n",
    "    tensessions[:, 40:, :], pred, max_flooring=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's plot some simple performance metrics, like voxelwise correlation. These next few slides require Pycortex, you can skip them if you don't have it installed for our subjects on your machine. We assume here that you have the surface for UTS03 from our dataset in order to plot it. Here we filter voxels that are not language selective out by only selecting for voxels that have $cc_{max}$ > 0.35, and then we plot the resulting flatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for ei, i in enumerate(cc_max):\n",
    "    if i <= 0.35:\n",
    "        acc.append(np.nan)\n",
    "    else:\n",
    "        acc.append(corrs_unnorm[ei])\n",
    "acc = np.array(acc)\n",
    "vol = cortex.Volume(acc, 'UTS03', 'UTS03', vmin=-1, vmax=1)\n",
    "cortex.quickshow(vol, with_colorbar=True, linewidth=4,\n",
    "                 thick=1, with_curvature=True, with_rois=False)\n",
    "plt.title(\"Voxelwise Correlation Coefficient ($CC_{abs}$)\", size=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the regions in cortex that have the most room for improvement based on the noise ceiling, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "acc2 = []\n",
    "for ei, i in enumerate(cc_max):\n",
    "    if i <= 0.35:\n",
    "        acc.append(np.nan)\n",
    "        acc2.append(np.nan)\n",
    "    else:\n",
    "        acc.append(cc_max[ei] - corrs_unnorm[ei])\n",
    "        acc2.append(cc_max[ei])\n",
    "acc = np.array(acc)\n",
    "acc2 = np.array(acc2)\n",
    "\n",
    "corr2d = cortex.Volume2D(acc, acc2, 'UTS03', 'UTS03', vmin=0, vmax=0.5, vmin2=0.2, vmax2=0.7,\n",
    "                         cmap=\"plasma_alpha\")\n",
    "cortex.quickshow(corr2d, with_curvature=True, with_labels=False,\n",
    "                 with_rois=False, linewidth=5, with_colorbar=False)\n",
    "plt.title(\n",
    "    \"Room for Improvement ($CC_{max}$ - $CC_{abs}$) vs. $CC_{max}$\", size=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at individual voxelwise timecourses and see how well we were able to predict them. Here's one voxel from this individual's right precuneus that we presented in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 4))\n",
    "data = [i.T[55879] for i in tensessions[:, 40:, :]]\n",
    "\n",
    "for i in tensessions[:, 40:, :]:\n",
    "    plt.plot(i.T[55879], alpha=0.12, color='black')\n",
    "mean_data = np.mean(data, axis=0)\n",
    "plt.plot(mean_data, 'k--', alpha=0.8)\n",
    "plt.plot(pred.T[55879], color='red', alpha=0.8)\n",
    "plt.xlabel(\"TR\", size=16)\n",
    "plt.ylabel(\"Z-scored Response\", size=16)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Encoding Model\n",
    "\n",
    "Next, we will show how to use the joint speech and semantic stacked encoding model, based on [Lin et al.](https://pubmed.ncbi.nlm.nih.gov/37163111/). We start by taking the layerwise residual covariance matrix $\\mathcal{R}$, which has been provided, and solving the quadratic program given in the paper. The resulting output gives us a set of attributions $\\alpha^{v}$, stored in `acc_alphas`, per voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def quadratic_program_solver(R):\n",
    "    k = len(R)\n",
    "\n",
    "    P = matrix(np.array(R))\n",
    "    q = matrix(np.zeros(k))\n",
    "\n",
    "    # alpha_j â‰¥ 0 Constraint\n",
    "    G = matrix(-np.eye(k))\n",
    "    h = matrix(np.zeros(k))\n",
    "\n",
    "    # sum(alpha_j) = 1 Constraint\n",
    "    A = matrix(np.ones((1, k)))\n",
    "    b = matrix(np.ones(1))\n",
    "\n",
    "    # Solve the quadratic program\n",
    "    solvers.options['show_progress'] = False\n",
    "    solution = solvers.qp(P, q, G, h, A, b)\n",
    "\n",
    "    return np.array(solution['x']).flatten()\n",
    "\n",
    "\n",
    "# From stacked_regression folder\n",
    "R = joblib.load(\"stacked_reg_R_mat_audio_S03.jbl\")\n",
    "R = R[:, 1:, 1:]  # Don't use initial embedding layer, causes attribution issues\n",
    "acc_alphas = []\n",
    "for ei, i in enumerate(R):\n",
    "    alphas = quadratic_program_solver(i)\n",
    "    acc_alphas.append(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the final stacked encoding model given by $ \\sum_{j=1}^{k} \\alpha_{h_j}^{v}  f^{v,s}_{h_j}\\left(\\boldsymbol{x}_j\\right)$. We provide the predictions in several files on the Box for readability, but they can be computed similarly to what was done in the previous section for the OPT weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All loaded files here are from the wheretheressmoke_preds subdirectory of the stacked_regression folder.\n",
    "acc_alphas = np.array(acc_alphas)\n",
    "pred = np.zeros((790, NUM_VOX))\n",
    "for ei, i in enumerate(acc_alphas.T[:16]):\n",
    "    layer_preds = joblib.load(\"test_preds_whisper_\" + str(2*ei+2) + \"_S03.jbl\")\n",
    "    for vox in range(NUM_VOX):\n",
    "        pred[:, vox] += layer_preds[:, vox] * acc_alphas[vox][ei]\n",
    "llama_layer_preds = joblib.load(\"test_preds_llama30B18_S03.jbl\")\n",
    "for vox in range(NUM_VOX):\n",
    "    pred[:, vox] += layer_preds[:, vox] * acc_alphas[vox][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then evaluate our stacked model on some validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth val/test responses, also from stacked_regression folder\n",
    "gt = joblib.load(\"S03_test_stories_avg_resp.jbl\")\n",
    "\n",
    "stacked_acc_val_stacked = []\n",
    "for i in range(NUM_VOX):\n",
    "    stacked_acc_val_stacked.append(np.corrcoef(\n",
    "        gt[:, i][251:], pred[:, i][251:])[0][1])\n",
    "\n",
    "stacked_acc_val_sem = []\n",
    "for i in range(NUM_VOX):\n",
    "    stacked_acc_val_sem.append(np.corrcoef(\n",
    "        gt[:, i][251:], llama_layer_preds[:, i][251:])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this validation performance to generate a validation mask which we then use to decide which voxels use the stacked predictions instead of the semantic model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_acc_test_stacked = []\n",
    "stacked_acc_test_sem = []\n",
    "val_mask = np.array(stacked_acc_val_stacked) - \\\n",
    "    np.array(stacked_acc_val_sem) > 0.05\n",
    "for i in range(95556):\n",
    "    if val_mask[i]:\n",
    "        stacked_acc_test_stacked.append(np.corrcoef(\n",
    "            gt[:, i][:251], pred[:, i][:251])[0][1])\n",
    "    else:\n",
    "        stacked_acc_test_stacked.append(np.corrcoef(\n",
    "            gt[:, i][:251], llama_layer_preds[:, i][:251])[0][1])\n",
    "    stacked_acc_test_sem.append(np.corrcoef(\n",
    "        gt[:, i][:251], llama_layer_preds[:, i][:251])[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot how much better the stacked model is over the semantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = cortex.Volume(np.array(stacked_acc_test_stacked) -\n",
    "                    np.array(stacked_acc_test_sem), 'UTS03', 'UTS03', vmin=-0.5, vmax=0.5)\n",
    "cortex.quickshow(vol, with_colorbar=False, linewidth=4, thick=1,\n",
    "                 with_curvature=True, with_rois=True, height=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the convex attributions of the stacked model to see how represetations shift from preferring earlier speech model layers to later speech model layers. This can be visualized by a center-of-mass statistic of the attibution vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = []\n",
    "for i in range(len(acc_alphas)):\n",
    "    com_tmp = 0\n",
    "    for j in range(16):\n",
    "        com_tmp += j * acc_alphas[i][j]\n",
    "    com.append(com_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can plot this center-of-mass statistic on a flatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = cortex.Volume(np.array(com), 'UTS03', 'UTS03',\n",
    "                    vmin=0, vmax=16, cmap='fire')\n",
    "cortex.quickshow(vol, with_colorbar=True, linewidth=4,\n",
    "                 thick=1, with_curvature=True, with_rois=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Semantic Feature Extraction\n",
    "\n",
    "Here we use some code that handles the tedious tokenization aspect of building LLM encoding models with our data. Our dataset is annotated at a per-word level, instead of a per-token level, so efforts need to be made to align the word annotations temporally with the features of the model. This can be done naively by using a fixed-length context window that changes per word, but this is _very slow_. Since we are dealing with large models on a tight computational budget, we want to avoid pointless recomputation as much as possible. We do this with a dynamic programming approach to minimize the number of forward passes that we will need to perform during actual feature extraction. Here, we build a set of dictionaries, `text_dict`, `text_dict2` and `text_dict3` that mark which contexts actually need to be run through the model. We use a non-fixed length sliding window which grows and shrinks at fixed intervals to minimize the number of forward passes that are required. The process can then be repeated in reverse to get the hidden state features in the proper order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPT\n",
    "\n",
    "# These files are located in the story_data folder of the Box\n",
    "# Load TextGrids containing story annotations\n",
    "grids = joblib.load(\"grids_huge.jbl\")\n",
    "# Load TRFiles containing TR information\n",
    "trfiles = joblib.load(\"trfiles_huge.jbl\")\n",
    "\n",
    "# We'll build an encoding model using this set of stories for this tutorial.\n",
    "train_stories = ['adollshouse', 'adventuresinsayingyes', 'alternateithicatom', 'avatar', 'buck', 'exorcism',\n",
    "                 'eyespy', 'fromboyhoodtofatherhood', 'hangtime', 'haveyoumethimyet', 'howtodraw', 'inamoment',\n",
    "                 'itsabox', 'legacy', 'naked', 'odetostepfather', 'sloth',\n",
    "                 'souls', 'stagefright', 'swimmingwithastronauts', 'thatthingonmyarm', 'theclosetthatateeverything',\n",
    "                 'tildeath', 'undertheinfluence']\n",
    "\n",
    "test_stories = [\"wheretheressmoke\"]\n",
    "\n",
    "# Filter out the other stories for the tutorial\n",
    "for story in list(grids):\n",
    "    if story not in (train_stories + test_stories):\n",
    "        del grids[story]\n",
    "        del trfiles[story]\n",
    "\n",
    "# Make datasequence for story\n",
    "wordseqs = make_word_ds(grids, trfiles)\n",
    "\n",
    "# We will be using a sliding context window with minimum size 256 words that increases until size 512 words.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"facebook/opt-125m\")  # Same tokenizer for all sizes\n",
    "\n",
    "# Make dictionary to align tokens and words\n",
    "text_dict, text_dict2, text_dict3 = generate_efficient_feat_dicts_opt(\n",
    "    wordseqs, tokenizer, 256, 512)\n",
    "\n",
    "\n",
    "# We are going to use the 125m parameter model for this tutorial, but any size should work\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-125m\")\n",
    "\n",
    "# We will extract features from the 9th layer of the model\n",
    "LAYER_NUM = 9\n",
    "\n",
    "start_time = time.time()\n",
    "for phrase in text_dict2:\n",
    "    if text_dict2[phrase]:\n",
    "        inputs = {}\n",
    "        inputs['input_ids'] = torch.tensor([text_dict[phrase]]).int()\n",
    "        inputs['attention_mask'] = torch.ones(inputs['input_ids'].shape)\n",
    "        out = list(model(**inputs, output_hidden_states=True)[2])\n",
    "        out = out[LAYER_NUM][0].cpu().detach().numpy()\n",
    "        out = np.array(out)\n",
    "        this_key = tuple(inputs['input_ids'][0].cpu().detach().numpy())\n",
    "        acc_true = 0\n",
    "        for ei, i in enumerate(this_key):\n",
    "            if this_key[:ei+1] in text_dict3:\n",
    "                acc_true += 1\n",
    "                text_dict3[this_key[:ei+1]] = out[ei, :]\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Feature extraction took\", end_time -\n",
    "      start_time, \"seconds on\", model.device)\n",
    "# Convert back from dictionary to matrix\n",
    "feats = convert_to_feature_mats_opt(wordseqs, tokenizer, 256, 512, text_dict3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these features to create new encoding model weights and test them on some held-out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same preprocessing as before\n",
    "# trim off a little more for artifact correction at test time.\n",
    "\n",
    "# Training data\n",
    "Rstim = np.nan_to_num(np.vstack(\n",
    "    [ridge_utils.npp.zs(feats[story][10:-5]) for story in train_stories]))\n",
    "\n",
    "# Test data\n",
    "Pstim = np.nan_to_num(np.vstack([ridge_utils.npp.zs(\n",
    "    feats[story][trim_start:-trim_end]) for story in test_stories]))\n",
    "\n",
    "# Add FIR delays\n",
    "delRstim = make_delayed(Rstim, delays)\n",
    "delPstim = make_delayed(Pstim, delays)\n",
    "\n",
    "# Equally log-spaced ridge parameters between 10 and 10000.\n",
    "alphas = np.logspace(1, 4, 15)\n",
    "# Number of cross-validation ridge regression runs. You can lower this number to increase speed.\n",
    "nboots = 3\n",
    "\n",
    "# Get response data\n",
    "# Located in story_responses folder\n",
    "resp_dict = joblib.load(\"UTS03_responses.jbl\")\n",
    "Rresp = np.vstack([resp_dict[story] for story in train_stories])\n",
    "Presp = np.vstack([resp_dict[story][40:] for story in test_stories])\n",
    "\n",
    "# Bootstrap chunking parameters\n",
    "chunklen = 20\n",
    "nchunks = int(len(Rresp) * 0.25 / chunklen)\n",
    "\n",
    "# Run ridge regression - this might take some time\n",
    "wt, corr, alphas, bscorrs, valinds = bootstrap_ridge(delRstim, Rresp, delPstim, Presp,\n",
    "                                                     alphas, nboots, chunklen, nchunks,\n",
    "                                                     use_corr=False, single_alpha=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot the resulting test performance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = cortex.Volume(np.array(corr), 'UTS03', 'UTS03', vmin=-1, vmax=1, )\n",
    "cortex.quickshow(vol, with_colorbar=True, linewidth=4,\n",
    "                 thick=1, with_curvature=True, with_rois=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the tutorial. If you have additional questions about how to use our dataset, or about the paper, feel free to contact rjantonello@utexas.edu. If these data or models were helpful for your own work please cite our paper using the following BibTex citation:\n",
    "\n",
    "```\n",
    "@article{antonello2023scaling,\n",
    "  title={Scaling laws for language encoding models in fMRI}, \n",
    "  author={Richard J. Antonello and Aditya R. Vaidya and Alexander G. Huth},\n",
    "  journal={Advances in Neural Information Processing Systems},\n",
    "  volume={36},\n",
    "  year={2023}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
